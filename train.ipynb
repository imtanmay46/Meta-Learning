{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meta Learning\n",
    "\n",
    "ARC\n",
    "\n",
    "Tanmay Singh\n",
    "2021569\n",
    "CSAI\n",
    "Class of '25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import mplcyberpunk as mcy\n",
    "from tqdm.auto import tqdm\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib.colors import ListedColormap, Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_task(task_path):\n",
    "    with open(task_path, 'r') as f:\n",
    "        task = json.load(f)\n",
    "    return task\n",
    "\n",
    "def visualize_task(task, title_prefix=\"Original\", num_samples=None):\n",
    "    if num_samples is not None:\n",
    "        task = task[:num_samples]\n",
    "    \n",
    "    for idx, pair in enumerate(task):\n",
    "        input_grid = np.array(pair[\"input\"])\n",
    "        output_grid = np.array(pair[\"output\"])\n",
    "        \n",
    "        fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "        cmap = ListedColormap([\n",
    "            '#000', '#0074D9', '#FF4136', '#2ECC40', '#FFDC00',\n",
    "            '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'\n",
    "        ])\n",
    "        norm = Normalize(vmin=0, vmax=9)\n",
    "\n",
    "        axes[0].imshow(input_grid, cmap=cmap, norm=norm)\n",
    "        axes[0].set_title(f\"{title_prefix} Input {idx+1}\")\n",
    "        axes[1].imshow(output_grid, cmap=cmap, norm=norm)\n",
    "        axes[1].set_title(f\"{title_prefix} Output {idx+1}\")\n",
    "\n",
    "        for ax in axes:\n",
    "            ax.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "def plot_task(task):\n",
    "    examples = task['train']\n",
    "    n_examples = len(examples)\n",
    "    cmap = ListedColormap([\n",
    "        '#000', '#0074D9', '#FF4136', '#2ECC40', '#FFDC00',\n",
    "        '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'\n",
    "    ])\n",
    "    norm = Normalize(vmin=0, vmax=9)\n",
    "    fig, axes = plt.subplots(2, n_examples, figsize=(n_examples * 4, 8))\n",
    "    for i, example in enumerate(examples):\n",
    "        axes[0, i].imshow(example['input'], cmap=cmap, norm=norm)\n",
    "        axes[1, i].imshow(example['output'], cmap=cmap, norm=norm)\n",
    "        axes[0, i].axis('off')\n",
    "        axes[1, i].axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './data/arc_data/ARC-AGI-master/data/'\n",
    "training_dir = os.path.join(data_dir, 'training')\n",
    "evaluation_dir = os.path.join(data_dir, 'evaluation')\n",
    "\n",
    "val_split = 0.2\n",
    "random_seed = 42\n",
    "random.seed(random_seed)\n",
    "\n",
    "def load_json(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "train_files = [os.path.join(training_dir, f) for f in os.listdir(training_dir) if f.endswith('.json')]\n",
    "evaluation_files = [os.path.join(evaluation_dir, f) for f in os.listdir(evaluation_dir) if f.endswith('.json')]\n",
    "\n",
    "random.shuffle(train_files)\n",
    "train_files, val_files = train_test_split(train_files, test_size=val_split, random_state=random_seed)\n",
    "\n",
    "def process_files(file_list, key='train'):\n",
    "    dataset = []\n",
    "    for file_path in file_list:\n",
    "        data = load_json(file_path)\n",
    "        for item in data[key]:\n",
    "            dataset.append({\n",
    "                'input': item['input'],\n",
    "                'output': item['output']\n",
    "            })\n",
    "    return dataset\n",
    "\n",
    "train_dataset = process_files(train_files, key='train')\n",
    "val_dataset = process_files(val_files, key='train')\n",
    "eval_dataset = process_files(evaluation_files, key='test')\n",
    "\n",
    "output_dir = './data/arc_data/processed_data'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "with open(os.path.join(output_dir, 'train_dataset.json'), 'w') as f:\n",
    "    json.dump(train_dataset, f, indent=4)\n",
    "\n",
    "with open(os.path.join(output_dir, 'val_dataset.json'), 'w') as f:\n",
    "    json.dump(val_dataset, f, indent=4)\n",
    "\n",
    "with open(os.path.join(output_dir, 'eval_dataset.json'), 'w') as f:\n",
    "    json.dump(eval_dataset, f, indent=4)\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "print(f\"Evaluation samples: {len(eval_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_grid_uniform(grid, target_size=30, pad_value=10):\n",
    "    rows, cols = len(grid), len(grid[0]) if grid else 0\n",
    "\n",
    "    row_padding = (target_size - rows) // 2\n",
    "    col_padding = (target_size - cols) // 2\n",
    "\n",
    "    row_padding_extra = (target_size - rows) % 2\n",
    "    col_padding_extra = (target_size - cols) % 2\n",
    "\n",
    "    padded_grid = np.full((target_size, target_size), pad_value, dtype=int)\n",
    "\n",
    "    padded_grid[\n",
    "        row_padding : row_padding + rows, \n",
    "        col_padding : col_padding + cols\n",
    "    ] = grid\n",
    "\n",
    "    return padded_grid.tolist()\n",
    "\n",
    "def pad_dataset_uniform(dataset, target_size=30, pad_value=10):\n",
    "    padded_dataset = []\n",
    "    for task in dataset:\n",
    "        padded_task = {\n",
    "            \"input\": pad_grid_uniform(task[\"input\"], target_size, pad_value),\n",
    "            \"output\": pad_grid_uniform(task[\"output\"], target_size, pad_value)\n",
    "        }\n",
    "        padded_dataset.append(padded_task)\n",
    "    return padded_dataset\n",
    "\n",
    "output_dir = './data/arc_data/processed_data'\n",
    "\n",
    "with open(os.path.join(output_dir, 'train_dataset.json'), 'r') as f:\n",
    "    train_dataset = json.load(f)\n",
    "\n",
    "with open(os.path.join(output_dir, 'val_dataset.json'), 'r') as f:\n",
    "    val_dataset = json.load(f)\n",
    "\n",
    "with open(os.path.join(output_dir, 'eval_dataset.json'), 'r') as f:\n",
    "    eval_dataset = json.load(f)\n",
    "\n",
    "padded_train_dataset = pad_dataset_uniform(train_dataset, target_size=30, pad_value=10)\n",
    "padded_val_dataset = pad_dataset_uniform(val_dataset, target_size=30, pad_value=10)\n",
    "padded_eval_dataset = pad_dataset_uniform(eval_dataset, target_size=30, pad_value=10)\n",
    "\n",
    "with open(os.path.join(output_dir, 'padded_train_dataset.json'), 'w') as f:\n",
    "    json.dump(padded_train_dataset, f, indent=4)\n",
    "\n",
    "with open(os.path.join(output_dir, 'padded_val_dataset.json'), 'w') as f:\n",
    "    json.dump(padded_val_dataset, f, indent=4)\n",
    "\n",
    "with open(os.path.join(output_dir, 'padded_eval_dataset.json'), 'w') as f:\n",
    "    json.dump(padded_eval_dataset, f, indent=4)\n",
    "\n",
    "print(\"Padding complete!\")\n",
    "print(f\"Padded Training samples: {len(padded_train_dataset)}\")\n",
    "print(f\"Padded Validation samples: {len(padded_val_dataset)}\")\n",
    "print(f\"Padded Evaluation samples: {len(padded_eval_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_path = './data/arc_data/processed_data/train_dataset.json'\n",
    "task = load_task(task_path)\n",
    "\n",
    "visualize_task(task, title_prefix=\"Original\", num_samples = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_task_path = './data/arc_data/processed_data/padded_train_dataset.json'\n",
    "padded_task = load_task(padded_task_path)\n",
    "\n",
    "visualize_task(padded_task, title_prefix=\"Padded\", num_samples = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_grid(grid):\n",
    "    return [cell for row in grid for cell in row]\n",
    "\n",
    "def flatten_dataset(dataset):\n",
    "    flattened_dataset = []\n",
    "    for task in dataset:\n",
    "        flattened_task = {\n",
    "            \"input\": flatten_grid(task[\"input\"]),\n",
    "            \"output\": flatten_grid(task[\"output\"])\n",
    "        }\n",
    "        flattened_dataset.append(flattened_task)\n",
    "    return flattened_dataset\n",
    "\n",
    "flattened_train_dataset = flatten_dataset(padded_train_dataset)\n",
    "flattened_val_dataset = flatten_dataset(padded_val_dataset)\n",
    "flattened_eval_dataset = flatten_dataset(padded_eval_dataset)\n",
    "\n",
    "output_dir = './data/arc_data/processed_data'\n",
    "\n",
    "with open(os.path.join(output_dir, 'flattened_train_dataset.json'), 'w') as f:\n",
    "    json.dump(flattened_train_dataset, f, indent=4)\n",
    "\n",
    "with open(os.path.join(output_dir, 'flattened_val_dataset.json'), 'w') as f:\n",
    "    json.dump(flattened_val_dataset, f, indent=4)\n",
    "\n",
    "with open(os.path.join(output_dir, 'flattened_eval_dataset.json'), 'w') as f:\n",
    "    json.dump(flattened_eval_dataset, f, indent=4)\n",
    "\n",
    "print(\"Flattened datasets saved!\")\n",
    "print(f\"Flattened Training samples: {len(flattened_train_dataset)}\")\n",
    "print(f\"Flattened Validation samples: {len(flattened_val_dataset)}\")\n",
    "print(f\"Flattened Evaluation samples: {len(flattened_eval_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "NUM_EPOCHS = 100\n",
    "INNER_LR = 1e-4\n",
    "OUTER_LR = 1e-3\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlattenedARCDataset(Dataset):\n",
    "    def __init__(self, data, is_input=True):\n",
    "        self.data = data\n",
    "        self.is_input = is_input\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.is_input:\n",
    "            grid = self.data[idx][\"input\"]\n",
    "        else:\n",
    "            grid = self.data[idx][\"output\"]\n",
    "        return torch.tensor(grid, dtype=torch.float32)\n",
    "\n",
    "train_inputs = FlattenedARCDataset(flattened_train_dataset, is_input=True)\n",
    "train_outputs = FlattenedARCDataset(flattened_train_dataset, is_input=False)\n",
    "\n",
    "val_inputs = FlattenedARCDataset(flattened_val_dataset, is_input=True)\n",
    "val_outputs = FlattenedARCDataset(flattened_val_dataset, is_input=False)\n",
    "\n",
    "eval_inputs = FlattenedARCDataset(flattened_eval_dataset, is_input=True)\n",
    "eval_outputs = FlattenedARCDataset(flattened_eval_dataset, is_input=False)\n",
    "\n",
    "train_input_loader = DataLoader(train_inputs, batch_size=BATCH_SIZE, shuffle=True)\n",
    "train_output_loader = DataLoader(train_outputs, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "val_input_loader = DataLoader(val_inputs, batch_size=BATCH_SIZE, shuffle=False)\n",
    "val_output_loader = DataLoader(val_outputs, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "eval_input_loader = DataLoader(eval_inputs, batch_size=BATCH_SIZE, shuffle=False)\n",
    "eval_output_loader = DataLoader(eval_outputs, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MAMLTrainingPipeline:\n",
    "    def __init__(self, model, train_input_loader, train_output_loader, val_input_loader, val_output_loader, outer_optimizer, device, inner_lr=INNER_LR):\n",
    "        self.model = model\n",
    "        self.train_input_loader = train_input_loader\n",
    "        self.train_output_loader = train_output_loader\n",
    "        self.val_input_loader = val_input_loader\n",
    "        self.val_output_loader = val_output_loader\n",
    "        self.outer_optimizer = outer_optimizer\n",
    "        self.device = device\n",
    "        self.inner_lr = inner_lr\n",
    "\n",
    "    def compute_elementwise_loss(self, predicted, actual):\n",
    "        differences = torch.abs(predicted - actual)\n",
    "        total_loss = differences.sum()\n",
    "        avg_loss = total_loss / predicted.numel()\n",
    "        return avg_loss\n",
    "\n",
    "    def inner_loop(self, inputs, targets):\n",
    "        task_model = EncoderDecoderModel().to(self.device)\n",
    "        task_model.load_state_dict(self.model.state_dict())\n",
    "        inner_optimizer = optim.Adam(task_model.parameters(), lr=self.inner_lr)\n",
    "\n",
    "        task_model.train()\n",
    "        for _ in range(5):\n",
    "            inner_optimizer.zero_grad()\n",
    "            outputs = task_model(inputs)\n",
    "            loss = self.compute_elementwise_loss(outputs, targets)\n",
    "            loss.backward()\n",
    "            inner_optimizer.step()\n",
    "\n",
    "        return task_model\n",
    "\n",
    "    def outer_loop(self, num_epochs):\n",
    "        train_losses = []\n",
    "\n",
    "        for epoch in tqdm(range(1, num_epochs + 1), desc=\"Meta-Training\"):\n",
    "            self.model.train()\n",
    "            total_meta_loss = 0.0\n",
    "\n",
    "            for inputs, targets in tqdm(zip(self.train_input_loader, self.train_output_loader), desc=f\"Epoch {epoch} - Inner Loop\", leave=False):\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                adapted_model = self.inner_loop(inputs, targets)\n",
    "\n",
    "                adapted_model.eval()\n",
    "                meta_outputs = adapted_model(inputs)\n",
    "                meta_loss = self.compute_elementwise_loss(meta_outputs, targets)\n",
    "\n",
    "                meta_loss.backward()\n",
    "                total_meta_loss += meta_loss.item()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=5.0)\n",
    "            self.outer_optimizer.step()\n",
    "            self.outer_optimizer.zero_grad()\n",
    "\n",
    "            train_losses.append(total_meta_loss / len(self.train_input_loader))\n",
    "            print(f\"Epoch {epoch}: Train Loss = {train_losses[-1]:.4f}\")\n",
    "\n",
    "            epoch_model_path = os.path.join(\"./saved_models\", f\"meta_model_epoch_{epoch}.pth\")\n",
    "            torch.save(self.model.state_dict(), epoch_model_path)\n",
    "            # torch.save(self.model.state_dict(), f\"meta_model_epoch_{epoch}.pth\")\n",
    "\n",
    "        print(\"Meta-Training completed. Computing final validation loss.\")\n",
    "        val_losses = self.validate()\n",
    "        print(f\"Final Validation Loss: {sum(val_losses) / len(val_losses):.4f}\")\n",
    "\n",
    "        best_model_path = os.path.join(\"./saved_models\", \"best_meta_model.pth\")\n",
    "        torch.save(self.model.state_dict(), best_model_path)\n",
    "        # torch.save(self.model.state_dict(), \"best_meta_model.pth\")\n",
    "        print(\"Model saved as 'best_meta_model.pth'.\")\n",
    "\n",
    "        return train_losses, val_losses\n",
    "\n",
    "    def validate(self):\n",
    "        self.model.eval()\n",
    "        batch_losses = []\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (inputs, targets) in enumerate(zip(self.val_input_loader, self.val_output_loader), 1):\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.compute_elementwise_loss(outputs, targets)\n",
    "                batch_losses.append(loss.item())\n",
    "                print(f\"Validation Batch {batch_idx}: Loss = {loss.item():.4f}\")\n",
    "\n",
    "        return batch_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EncoderDecoderModel().to(DEVICE)\n",
    "outer_optimizer = optim.AdamW(model.parameters(), lr=OUTER_LR, weight_decay=0.01)\n",
    "\n",
    "pipeline = MAMLTrainingPipeline(\n",
    "    model,\n",
    "    train_input_loader,\n",
    "    train_output_loader,\n",
    "    val_input_loader,\n",
    "    val_output_loader,\n",
    "    outer_optimizer,\n",
    "    DEVICE\n",
    ")\n",
    "\n",
    "train_losses, val_losses = pipeline.outer_loop(num_epochs=NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"cyberpunk\")\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label=\"Meta-Train Loss\", color=\"gold\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Meta-Training Loss\")\n",
    "plt.legend()\n",
    "mcy.add_gradient_fill()\n",
    "plt.show()\n",
    "\n",
    "plt.style.use(\"cyberpunk\")\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(val_losses, label=\"Validation Loss (Per Batch)\", color=\"coral\")\n",
    "plt.xlabel(\"Batches\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Validation Loss Per Batch\")\n",
    "plt.legend()\n",
    "mcy.add_gradient_fill()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Meta-Training completed. Final Validation Loss: {sum(val_losses) / len(val_losses):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
